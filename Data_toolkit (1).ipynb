{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smUGQEPwylao"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFCKaZpLwcya"
      },
      "outputs": [],
      "source": [
        "# Assignment on Data Toolkit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. What is NumPy, and why is it widely used in Python?\n",
        "\n",
        "NumPy (Numerical Python) is a library for numerical computing in Python.\n",
        "It provides support for arrays (both single-dimensional and multi-dimensional) and offers a wide variety of mathematical functions.\n",
        "NumPy is widely used because it enables efficient operations on large datasets and supports vectorized operations,\n",
        "making computations faster than using Python lists.\n"
      ],
      "metadata": {
        "id": "bL9CCSvlw7ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. How does broadcasting work in NumPy?\n",
        "Broadcasting in NumPy allows arrays of different shapes to be combined for operations like addition, multiplication, etc.\n",
        "If the dimensions of arrays are compatible (matching or one of them is 1),\n",
        "NumPy automatically \"stretches\" the smaller array along that dimension to match the larger array's shape.\n"
      ],
      "metadata": {
        "id": "G62SfYe9yKfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.What is a Pandas DataFrame?\n",
        "A DataFrame is a 2-dimensional, tabular data structure in Pandas, similar to an Excel spreadsheet or SQL table.\n",
        "It consists of rows and columns and allows data manipulation, filtering, and aggregation."
      ],
      "metadata": {
        "id": "-Y1zR3Zu1t32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.Explain the use of the groupby() method in Pandas.\n",
        "The groupby() method is used to split data into groups based on some criteria, apply a function to each group, and then combine the results.\n",
        "This is useful for aggregating data,\n",
        "such as calculating means or sums for different categories."
      ],
      "metadata": {
        "id": "DYGQc7kw184n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Why is Seaborn preferred for statistical visualizations?\n",
        "Seaborn is preferred for statistical visualizations because it provides high-level, easy-to-use functions\n",
        "for creating informative and attractive plots.\n",
        " It integrates well with Pandas DataFrames and supports complex visualizations like heatmaps, pair plots, and violin plots."
      ],
      "metadata": {
        "id": "JV0rYrHz2HkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6.What are the differences between NumPy arrays and Python lists?\n",
        "\n",
        "Speed: NumPy arrays are faster due to their fixed data type and low-level optimizations.\n",
        "Memory: Arrays use less memory compared to lists.\n",
        "Operations: NumPy supports vectorized operations, while lists require loops for similar tasks.\n",
        "Data Type: Lists can hold mixed data types; NumPy arrays typically contain elements of a single data type."
      ],
      "metadata": {
        "id": "syCf8xz40w8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7.What is a heatmap, and when should it be used?\n",
        "A heatmap is a data visualization technique used to represent the magnitude of a phenomenon using color gradients. .\n",
        "In a heatmap, individual values in a matrix or dataset are represented by varying colors,\n",
        "with different colors corresponding to different values. Typically, darker or more intense colors indicate higher values,\n",
        "while lighter or less intense colors represent lower values.\n",
        "When to use a heatmap:\n",
        "Data Density Visualization: Heatmaps are useful for visualizing the density or\n",
        "intensity of data points across a geographical area or within a dataset, such as:\n",
        "\n",
        "Showing which areas in a city have the highest concentration of traffic.\n",
        "Highlighting regions of a web page with the most user interaction (like click heatmaps).\n",
        "Correlation Between Variables: Heatmaps can help display correlations between different variables in a dataset,\n",
        " with color intensities representing the strength of the correlation. This is useful in:\n",
        "\n",
        "Financial analysis, where you might visualize how different stocks are correlated with each other.\n",
        "Identifying patterns in survey data or customer behavior.\n",
        "Time Series Analysis: Heatmaps are effective for visualizing changes over time, such as displaying temperature data or\n",
        "sales performance across different time intervals.\n",
        "Comparison Across Multiple Categories: In large datasets, heatmaps can be helpful to\n",
        "quickly compare values across categories and spot trends or\n",
        " outliers. For example:\n",
        "Comparing sales figures across regions and products.\n",
        "Analyzing customer preferences based on various attributes.\n",
        "Performance Monitoring: Heatmaps are often used to monitor the performance of systems,\n",
        "web traffic, or other dynamic datasets, providing immediate insights into areas that may require attention."
      ],
      "metadata": {
        "id": "XC3OLaIB2mMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8.What does the term “vectorized operation” mean in NumPy?\n",
        "A vectorized operation in NumPy is an operation performed on entire arrays rather than individual elements.\n",
        "This avoids the need for explicit loops and improves performance through underlying C implementations."
      ],
      "metadata": {
        "id": "1qxSVBC903Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. How does Matplotlib differ from Plotly?\n",
        "Matplotlib and Plotly are both popular Python libraries for data visualization, but they differ in functionality, ease of use, and the types of visualizations they best support. Here's a comparison between the two:\n",
        "\n",
        "1. Core Purpose and Use Cases\n",
        "Matplotlib:\n",
        "\n",
        "Primary Use: Static 2D plots.\n",
        "Best For: Traditional, publication-quality charts (e.g., line graphs, bar plots, histograms).\n",
        "Flexibility: Offers fine-grained control over plot elements.\n",
        "Use Case Examples: Scientific papers, basic plots, detailed customizations.\n",
        "Plotly:\n",
        "\n",
        "Primary Use: Interactive, dynamic plots.\n",
        "Best For: Interactive dashboards and web-based applications.\n",
        "Flexibility: Designed for interactivity, supports zooming, hovering, and saving to various formats.\n",
        "Use Case Examples: Web dashboards, real-time data visualization, interactive presentations.\n",
        "2. Interactivity\n",
        "Matplotlib:\n",
        "\n",
        "Static by Default: Produces static images (PNG, PDF, SVG).\n",
        "Interactivity: Limited interaction; requires extensions like mpld3 or Matplotlib's interactive backends (e.g., %matplotlib notebook in Jupyter).\n",
        "Plotly:\n",
        "\n",
        "Highly Interactive: Plots come with built-in interactivity (zoom, pan, hover tooltips).\n",
        "Web Integration: Works seamlessly with web applications and supports embedding in web pages.\n",
        "3. Ease of Use\n",
        "Matplotlib:\n",
        "\n",
        "Steeper Learning Curve: Requires more code and effort to create complex plots.\n",
        "Detailed Customization: Provides full control over plot details but can be verbose.\n",
        "Plotly:\n",
        "\n",
        "Simpler Syntax: Often requires less code for complex visualizations.\n",
        "High-Level API: Designed for ease of use, especially when creating interactive plots quickly.\n",
        "4. 3D Plotting\n",
        "Matplotlib:\n",
        "\n",
        "Supports 3D Plots: Through the mpl_toolkits.mplot3d module, but the interactivity is limited.\n",
        "Plotly:\n",
        "\n",
        "Advanced 3D Support: Provides smoother, more interactive 3D visualizations.\n",
        "5. Customization and Aesthetics\n",
        "Matplotlib:\n",
        "\n",
        "High Customizability: Nearly every element can be modified with detailed control.\n",
        "Classic Look: Default styles are more traditional but can be modified with themes.\n",
        "Plotly:\n",
        "\n",
        "Modern Look: Attractive, polished visuals by default.\n",
        "Templates: Easy-to-use themes for quick styling.\n",
        "6. Performance\n",
        "Matplotlib:\n",
        "\n",
        "Efficient for Small to Medium Data: Best for static plots and smaller datasets.\n",
        "Performance Issues: Can struggle with large datasets or complex interactive plots.\n",
        "Plotly:\n",
        "\n",
        "Handles Large Data Sets Well: Optimized for large-scale interactive visualizations.\n",
        "Web-Based Performance: Works efficiently in web browsers.\n",
        "7. Libraries Built on Them\n",
        "Matplotlib:\n",
        "\n",
        "Seaborn: Built on top of Matplotlib for statistical plotting.\n",
        "Pandas Plotting: Pandas' plot() function uses Matplotlib as the backend.\n",
        "Plotly:\n",
        "\n",
        "Dash: Framework for building interactive web dashboards using Plotly.\n",
        "Cufflinks: Bridges Plotly with Pandas for quick plotting.\n",
        "8. Export Options\n",
        "Matplotlib:\n",
        "\n",
        "Supports exporting to various static formats: PNG, PDF, SVG, EPS.\n",
        "Plotly:\n",
        "\n",
        "Supports exporting to static images (PNG, JPG, PDF) and interactive formats (HTML, JSON).\n",
        "Summary Table\n",
        "Feature\tMatplotlib\tPlotly\n",
        "Use Case\tStatic, detailed plots\tInteractive, dynamic plots\n",
        "Interactivity\tLimited\tBuilt-in, highly interactive\n",
        "Ease of Use\tSteeper learning curve\tEasier to create interactive plots\n",
        "Customization\tDetailed control\tModern themes, less verbose\n",
        "3D Support\tBasic 3D plotting\tAdvanced interactive 3D plots\n",
        "Best For\tScientific papers, static reports\tDashboards, web apps, presentations\n"
      ],
      "metadata": {
        "id": "uwTUP6ws3NN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10.What is the significance of hierarchical indexing in Pandas?\n",
        "Hierarchical indexing (also known as MultiIndexing) in Pandas allows you to have multiple levels of indexing on a DataFrame or Series.\n",
        "This enables you to represent data with multiple dimensions in a compact and intuitive manner.\n",
        "\n",
        "Significance of Hierarchical Indexing:\n",
        "Better Data Organization:\n",
        "\n",
        "It allows you to group and organize data along multiple dimensions (e.g., regions and cities, years and months).\n",
        "For instance, you can index first by country and then by city within each country.\n",
        "Enhanced Data Analysis:\n",
        "\n",
        "Hierarchical indexing simplifies slicing, filtering, and grouping operations across multiple levels.\n",
        "You can easily access subsets of data based on specific index levels.\n",
        "Compact Representation:\n",
        "\n",
        "It reduces redundancy in storing and displaying data with multiple dimensions.\n",
        "Instead of creating separate columns for multiple categories,\n",
        "hierarchical indexing stores them efficiently as multi-level indices.\n",
        "Flexible Data Manipulation:\n",
        "\n",
        "You can perform operations like aggregation or transformation at different levels of the hierarchy.\n",
        "For example, summing data by country first, then drilling down to city-level details.\n",
        "Improved Readability:\n",
        "\n",
        "The hierarchical structure makes complex datasets easier to interpret by providing a natural, nested organization.\n",
        "Pivoting and Reshaping:\n",
        "\n",
        "Hierarchical indexing facilitates pivoting and reshaping operations (e.g., using .stack() and .unstack()).\n",
        "Example of Hierarchical Indexing in Pandas:\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame with hierarchical indexing\n",
        "data = pd.DataFrame({\n",
        "    'Sales': [100, 150, 200, 250],\n",
        "    'Profit': [20, 30, 50, 60]\n",
        "}, index=[['India', 'India', 'USA', 'USA'], ['Mumbai', 'Delhi', 'New York', 'Los Angeles']])\n",
        "\n",
        "data.index.names = ['Country', 'City']\n",
        "\n",
        "print(data)\n",
        "Output:\n",
        "\n",
        "markdown\n",
        "Copy code\n",
        "                  Sales  Profit\n",
        "Country City\n",
        "India   Mumbai      100      20\n",
        "        Delhi       150      30\n",
        "USA     New York    200      50\n",
        "        Los Angeles 250      60\n",
        "Accessing Data in Hierarchical Index:\n",
        "You can easily access specific subsets of data using the hierarchical index:\n",
        "\n",
        "# Accessing data for India\n",
        "print(data.loc['India'])\n",
        "\n",
        "# Accessing data for a specific city\n",
        "print(data.loc[('USA', 'New York')])\n",
        "Summary:\n",
        "Hierarchical indexing is a powerful feature in Pandas that allows for sophisticated data representation,\n",
        "making it easier to work with complex datasets that have multiple levels of grouping or categorization.\n",
        "\n",
        "#11. What is the role of Seaborn’s pairplot() function?\n",
        "The pairplot() function in Seaborn is used to create pairwise plots of numerical data within a dataset,\n",
        "making it easy to visualize relationships between multiple variables. It creates a grid of scatterplots and\n",
        "histograms (or KDE plots) to provide insights into pairwise relationships and\n",
        "the distribution of data across different variables.\n",
        "\n",
        "Role of pairplot() Function:\n",
        "Visualizing Pairwise Relationships:\n",
        "\n",
        "pairplot() generates scatterplots for each pair of numerical variables in the dataset,\n",
        "helping you quickly spot correlations or patterns.\n",
        "Displaying Distributions:\n",
        "\n",
        "Along the diagonal, pairplot() shows the distribution of each variable using histograms or\n",
        "kernel density estimation (KDE) plots.\n",
        "Categorical Differentiation:\n",
        "\n",
        "You can use the hue parameter to color-code points based on a categorical variable,\n",
        " making it easy to distinguish patterns within groups.\n",
        "Quick Data Exploration:\n",
        "\n",
        "It's a convenient way to perform an initial exploratory data analysis (EDA) to\n",
        "understand the relationships and distributions in your dataset.\n",
        "Customizable Plots:\n",
        "\n",
        "You can customize pairplot() to control aspects like plot kind, size, markers, and style to suit your visualization needs.\n",
        "Syntax of pairplot()\n",
        "python\n",
        "Copy code\n",
        "import seaborn as sns\n",
        "\n",
        "sns.pairplot(data, hue=None, kind='scatter', diag_kind='auto', markers=None, height=2.5)\n",
        "Parameters:\n",
        "\n",
        "data: The DataFrame containing numerical variables.\n",
        "hue: Categorical variable for coloring the plots.\n",
        "kind: Type of plot for off-diagonal elements. Options: 'scatter', 'kde', or 'reg' (default is 'scatter').\n",
        "diag_kind: Type of plot for diagonal elements. Options: 'auto', 'hist', or 'kde' (default is 'auto').\n",
        "markers: Marker styles for different categories if hue is used.\n",
        "height: Height of each facet (grid cell).\n",
        "Example of pairplot()\n",
        "python\n",
        "Copy code\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# Load a sample dataset\n",
        "iris = sns.load_dataset('iris')\n",
        "\n",
        "# Create a pairplot with 'species' as the hue\n",
        "sns.pairplot(iris, hue='species')\n",
        "Output:\n",
        "The pairplot() will generate a grid of scatterplots for each pair of numerical columns in the dataset,\n",
        " with the diagonal showing the distribution of each variable and the points colored by the 'species' column."
      ],
      "metadata": {
        "id": "AlUrRBR23krH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12. What is the purpose of the describe() function in Pandas?\n",
        "The describe() function in Pandas is used to generate summary statistics for numerical and categorical data in a DataFrame or Series. It provides a quick overview of key statistical measures, helping you understand the central tendency, dispersion, and distribution of the dataset.\n",
        "\n",
        "Purpose of describe() Function:\n",
        "Summarizing Numerical Data:\n",
        "\n",
        "By default, describe() provides descriptive statistics for numerical columns such as count, mean, standard deviation, minimum, 25th percentile, median (50th percentile), 75th percentile, and maximum.\n",
        "Summarizing Categorical Data:\n",
        "\n",
        "When applied to categorical or object-type data, it returns the count, unique values, top (most frequent) value, and frequency of the top value.\n",
        "Quick Data Analysis:\n",
        "\n",
        "It offers an easy way to quickly inspect the statistical characteristics of your dataset during exploratory data analysis (EDA).\n",
        "Identifying Data Issues:\n",
        "\n",
        "Helps identify potential data quality issues, such as missing values, outliers, or inconsistent data ranges.\n",
        "Syntax of describe()\n",
        "python\n",
        "Copy code\n",
        "DataFrame.describe(percentiles=None, include=None, exclude=None)\n",
        "Parameters:\n",
        "\n",
        "percentiles: Specifies which percentiles to include (default is [0.25, 0.5, 0.75]).\n",
        "include: Specifies the data types to include (e.g., ['object'], ['number'], ['category']).\n",
        "exclude: Specifies the data types to exclude.\n",
        "Example of describe() for Numerical Data\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with numerical data\n",
        "df = pd.DataFrame({\n",
        "    'Age': [23, 25, 28, 30, 35],\n",
        "    'Salary': [50000, 60000, 70000, 80000, 90000]\n",
        "})\n",
        "\n",
        "# Descriptive statistics for numerical columns\n",
        "print(df.describe())\n",
        "Output:\n",
        "\n",
        "shell\n",
        "Copy code\n",
        "             Age        Salary\n",
        "count   5.000000      5.000000\n",
        "mean   28.200000  70000.000000\n",
        "std     4.712993  15811.388301\n",
        "min    23.000000  50000.000000\n",
        "25%    25.000000  60000.000000\n",
        "50%    28.000000  70000.000000\n",
        "75%    30.000000  80000.000000\n",
        "max    35.000000  90000.000000\n",
        "Example of describe() for Categorical Data\n",
        "python\n",
        "Copy code\n",
        "# Sample DataFrame with categorical data\n",
        "df_cat = pd.DataFrame({\n",
        "    'Department': ['Sales', 'HR', 'Sales', 'IT', 'IT']\n",
        "})\n",
        "\n",
        "# Descriptive statistics for categorical columns\n",
        "print(df_cat.describe(include='object'))\n",
        "Output:\n",
        "\n",
        "css\n",
        "Copy code\n",
        "       Department\n",
        "count           5\n",
        "unique          3\n",
        "top          Sales\n",
        "freq            2\n",
        "\n",
        "#13. Why is handling missing data important in Pandas?\n",
        "\n",
        "Handling missing data in Pandas is crucial because missing values can lead to inaccurate analysis, unreliable results, and errors in computations or visualizations. Data in real-world applications often comes with missing or incomplete entries due to various reasons, such as data entry errors, sensor failures, or incomplete surveys. Therefore, effectively dealing with missing data ensures that your analyses are valid and your models are robust.\n",
        "\n",
        "Reasons Why Handling Missing Data is Important\n",
        "Ensures Data Integrity:\n",
        "\n",
        "Missing data can compromise the integrity and quality of your dataset. Proper handling ensures that analyses and conclusions are based on complete and consistent data.\n",
        "Prevents Errors in Computation:\n",
        "\n",
        "Many operations (e.g., arithmetic calculations, aggregations) can produce NaN results or errors if missing values are present. Handling missing data helps prevent unexpected computation issues.\n",
        "Improves Model Performance:\n",
        "\n",
        "Machine learning models cannot handle missing values directly and may perform poorly if missing data is ignored. Properly imputing or removing missing values ensures better model accuracy and reliability.\n",
        "Preserves Statistical Validity:\n",
        "\n",
        "Missing data can introduce bias or affect the representativeness of the dataset. Appropriate handling methods (e.g., imputation) maintain the validity of statistical analyses.\n",
        "Enhances Visualization Clarity:\n",
        "\n",
        "Plots and charts can be misleading or incomplete when missing values are not addressed. Handling missing data ensures visualizations accurately represent the dataset.\n",
        "Facilitates Data Cleaning and Preprocessing:\n",
        "\n",
        "Handling missing data is a fundamental step in the data cleaning process, preparing the dataset for analysis or modeling.\n",
        "Prevents Data Loss:\n",
        "\n",
        "Simply removing rows with missing data can lead to the loss of valuable information. Thoughtful handling (e.g., imputing values) can retain more data for analysis.\n",
        "Common Techniques for Handling Missing Data in Pandas\n",
        "Detecting Missing Data:\n",
        "\n",
        "Use isna() or isnull() to detect missing values:\n",
        "python\n",
        "Copy code\n",
        "df.isna()\n",
        "Dropping Missing Data:\n",
        "\n",
        "Remove rows or columns with missing values using dropna():\n",
        "python\n",
        "Copy code\n",
        "df.dropna()\n",
        "Filling Missing Data (Imputation):\n",
        "\n",
        "Replace missing values with specific values or statistical measures (mean, median, mode) using fillna():\n",
        "python\n",
        "Copy code\n",
        "df['column'].fillna(df['column'].mean(), inplace=True)\n",
        "Forward Fill / Backward Fill:\n",
        "\n",
        "Use previous or subsequent values to fill missing data:\n",
        "python\n",
        "Copy code\n",
        "df.fillna(method='ffill')  # Forward fill\n",
        "df.fillna(method='bfill')  # Backward fill\n",
        "Interpolation:\n",
        "\n",
        "Estimate missing values based on other data points:\n",
        "python\n",
        "Copy code\n",
        "df['column'].interpolate()\n",
        "Example of Handling Missing Data\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Sample DataFrame with missing values\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, None, 30, None],\n",
        "    'Salary': [50000, 60000, None, 80000]\n",
        "})\n",
        "\n",
        "# Detect missing values\n",
        "print(df.isnull())\n",
        "\n",
        "# Fill missing values in 'Age' with the median\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "\n",
        "# Drop rows where 'Salary' is missing\n",
        "df.dropna(subset=['Salary'], inplace=True)\n",
        "\n",
        "print(df)\n",
        "\n",
        "#14. What are the benefits of using Plotly for data visualization?\n",
        "Plotly is a powerful, versatile, and interactive data visualization library that offers significant advantages for creating high-quality visualizations. It is widely used in data science, analytics, and web applications. Plotly supports Python, R, JavaScript, and other programming languages, making it a popular choice for a wide range of users.\n",
        "\n",
        "Benefits of Using Plotly for Data Visualization\n",
        "Interactive Visualizations\n",
        "Plotly generates interactive charts by default, enabling features like zooming, panning, hovering, and selecting data points.\n",
        "Enhances user experience by allowing deeper exploration of data without re-rendering the plot.\n",
        "Variety of Chart Types\n",
        "Offers a broad range of visualization options, including:\n",
        "Line charts, bar charts, scatter plots\n",
        "Pie charts, histograms, box plots\n",
        "Heatmaps, choropleth maps, 3D plots, and more\n",
        "Suitable for basic visualizations as well as complex, specialized plots.\n",
        "Publication-Quality Graphics\n",
        "Creates aesthetically appealing, high-resolution plots that are suitable for presentations, reports, and publications.\n",
        "Customizable color schemes, fonts, labels, and annotations ensure professional-quality output.\n",
        "Easy Integration with Dashboards\n",
        "Integrates seamlessly with Dash, a Python framework by Plotly for building interactive web-based dashboards and applications.\n",
        "Enables the creation of real-time, interactive data dashboards for data monitoring and decision-making.\n",
        "Cross-Platform and Multi-Language Support\n",
        "Supports multiple languages including Python, R, and JavaScript.\n",
        "Provides compatibility with web applications, Jupyter notebooks, and standalone scripts.\n",
        "Supports 3D and Geographical Plots\n",
        "Facilitates the creation of 3D plots, surface plots, and maps (geographical visualizations).\n",
        "Useful for visualizing spatial data, scientific data, and complex datasets.\n",
        "Seamless Export Options\n",
        "Easily export visualizations to various formats like PNG, SVG, PDF, and HTML.\n",
        "HTML export allows sharing interactive plots via web browsers without needing additional software.\n",
        "Customization and Flexibility\n",
        "Highly customizable: users can modify every aspect of the plot, including axes, legends, colors, markers, and annotations.\n",
        "Supports themes and templates for consistent styling.\n",
        "Integration with Pandas and NumPy\n",
        "Works well with data manipulation libraries like Pandas and NumPy.\n",
        "Simplifies the process of visualizing dataframes directly.\n",
        "Hover and Tooltip Features\n",
        "Displays detailed information on hover, such as data values and metadata.\n",
        "Enhances the depth of data exploration without cluttering the visualization.\n",
        "Community and Documentation\n",
        "Plotly has an active community and extensive documentation, making it easier to get help and find resources.\n",
        "Numerous examples and tutorials are available to support learning and troubleshooting.\n",
        "Offline and Online Support\n",
        "Can generate plots both online (using Plotly’s cloud service) and offline (locally).\n",
        "Offline mode is ideal for privacy-sensitive projects or when working without an internet connection.\n",
        "Example of Plotly Visualization in Python\n",
        "python\n",
        "Copy code\n",
        "import plotly.express as px\n",
        "\n",
        "# Sample data\n",
        "df = px.data.iris()\n",
        "\n",
        "# Create an interactive scatter plot\n",
        "fig = px.scatter(df, x='sepal_width', y='sepal_length', color='species',\n",
        "                 title='Iris Sepal Dimensions')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "\n",
        "#15. A How does NumPy handle multidimensional arrays?\n",
        "\n",
        "NumPy, short for Numerical Python, is a powerful Python library designed for efficient handling and computation of multidimensional arrays, known as ndarrays (N-dimensional arrays). These arrays are a fundamental structure for scientific computing, offering significant performance advantages over Python’s native lists.\n",
        "\n",
        "Key Features of NumPy’s Multidimensional Arrays\n",
        "Efficient Memory Layout\n",
        "NumPy arrays are stored in a contiguous block of memory, which makes them much faster than Python lists for numerical operations.\n",
        "Data is stored in a homogeneous format (all elements of the same data type), optimizing memory usage and computation speed.\n",
        "N-Dimensional Structure\n",
        "NumPy supports arrays with any number of dimensions:\n",
        "1D Array (vector): [1, 2, 3]\n",
        "2D Array (matrix): [[1, 2, 3], [4, 5, 6]]\n",
        "3D Array (tensor): [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]\n",
        "The dimensions (shape) of an array are represented as a tuple of integers.\n",
        "Array Attributes\n",
        "ndarray objects come with helpful attributes:\n",
        "shape: Returns the dimensions of the array.\n",
        "ndim: Returns the number of dimensions (axes).\n",
        "dtype: Returns the data type of array elements.\n",
        "size: Returns the total number of elements.\n",
        "itemsize: Returns the size (in bytes) of each element.\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import numpy as np\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "print(arr.shape)    # Output: (2, 3)\n",
        "print(arr.ndim)     # Output: 2\n",
        "print(arr.dtype)    # Output: int32 (or int64 depending on system)\n",
        "print(arr.size)     # Output: 6\n",
        "print(arr.itemsize) # Output: 4 (bytes per integer element)\n",
        "Indexing and Slicing\n",
        "NumPy supports intuitive indexing and slicing for accessing elements in multidimensional arrays.\n",
        "You can access elements using indices for each dimension.\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "arr = np.array([[10, 20, 30], [40, 50, 60]])\n",
        "print(arr[0, 1])  # Output: 20 (first row, second column)\n",
        "\n",
        "# Slicing\n",
        "print(arr[:, 1])  # Output: [20 50] (all rows, second column)\n",
        "Broadcasting\n",
        "Broadcasting allows operations between arrays of different shapes without explicitly reshaping them.\n",
        "NumPy automatically expands the smaller array's dimensions to match the larger one.\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "b = np.array([1, 2, 3])\n",
        "print(a + b)\n",
        "# Output:\n",
        "# [[ 2  4  6]\n",
        "#  [ 5  7  9]]\n",
        "Vectorized Operations\n",
        "NumPy supports vectorized operations, which apply operations element-wise across arrays. This avoids the need for explicit loops and improves performance.\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "arr = np.array([[1, 2], [3, 4]])\n",
        "print(arr * 2)  # Output: [[2, 4], [6, 8]]\n",
        "Reshaping Arrays\n",
        "Arrays can be reshaped to different dimensions without changing the data using reshape().\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "arr = np.array([1, 2, 3, 4, 5, 6])\n",
        "reshaped = arr.reshape(2, 3)\n",
        "print(reshaped)\n",
        "# Output:\n",
        "# [[1 2 3]\n",
        "#  [4 5 6]]\n",
        "Mathematical and Statistical Functions\n",
        "NumPy provides a wide range of built-in functions for mathematical operations (e.g., sum(), mean(), max(), min(), std()).\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6]])\n",
        "print(arr.mean(axis=0))  # Output: [2.5 3.5 4.5] (mean along columns)\n",
        "Advanced Indexing and Masking\n",
        "NumPy supports boolean indexing and masking for filtering data.\n",
        "Example:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "arr = np.array([1, 2, 3, 4, 5])\n",
        "print(arr[arr > 2])  # Output: [3 4 5]\n",
        "\n",
        "#16.A What is the role of Bokeh in data visualization?\n",
        "Let's tackle both parts of your question: the role of Bokeh in data visualization and the difference between apply() and map() in Pandas.\n",
        "\n",
        "1. The Role of Bokeh in Data Visualization\n",
        "Bokeh is a Python library designed for creating interactive, web-ready visualizations. It is particularly useful for large datasets and dashboards that need to be shared or deployed on web applications.\n",
        "\n",
        "Key Features of Bokeh:\n",
        "Interactive Visualizations\n",
        "\n",
        "Built-in tools for panning, zooming, hovering, and selecting data points.\n",
        "Enhances user experience with interactive exploration of data.\n",
        "Web-Ready Plots\n",
        "\n",
        "Generates HTML and JavaScript code for visualizations, making it easy to embed in web pages or applications.\n",
        "Compatible with web frameworks like Flask and Django.\n",
        "High-Performance with Large Datasets\n",
        "\n",
        "Optimized for rendering large datasets, ensuring smooth performance even with millions of data points.\n",
        "Variety of Chart Types\n",
        "\n",
        "Supports bar charts, line plots, scatter plots, heatmaps, histograms, and more.\n",
        "Provides support for advanced visualizations like geographical maps, network graphs, and 3D plots.\n",
        "Pythonic Syntax\n",
        "\n",
        "Easy to use for Python developers, with intuitive syntax similar to other popular libraries like Matplotlib and Seaborn.\n",
        "Customizable and Flexible\n",
        "\n",
        "Allows detailed customization of plot aesthetics, such as color, size, labels, and annotations.\n",
        "Integration with Other Tools\n",
        "\n",
        "Can be integrated with Pandas, NumPy, and Jupyter notebooks.\n",
        "Compatible with data dashboards using libraries like Panel and Holoviews.\n",
        "Example of a Simple Bokeh Plot:\n",
        "python\n",
        "Copy code\n",
        "from bokeh.plotting import figure, show\n",
        "\n",
        "# Sample data\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [6, 7, 2, 4, 5]\n",
        "\n",
        "# Create a figure\n",
        "p = figure(title=\"Simple Line Plot\", x_axis_label='X', y_axis_label='Y')\n",
        "\n",
        "# Add a line to the figure\n",
        "p.line(x, y, legend_label=\"Line\", line_width=2)\n",
        "\n",
        "# Show the plot\n",
        "show(p)\n",
        "\n",
        "\n",
        "\n",
        "#17. Explain the difference between apply() and map\n",
        "Both apply() and map() are used for applying functions to elements in a Pandas DataFrame or Series, but they have key differences in functionality and use cases.\n",
        "\n",
        "map() Function\n",
        "Scope: Used primarily with Pandas Series.\n",
        "Use Case: Suitable for mapping each value in a Series to a corresponding value via a dictionary, function, or Series.\n",
        "Best For: Replacing values or transforming data based on a mapping relationship.\n",
        "Examples of map():\n",
        "Mapping with a Dictionary:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'City': ['Mumbai', 'Delhi', 'Chennai']\n",
        "})\n",
        "\n",
        "city_map = {'Mumbai': 'Maharashtra', 'Delhi': 'Delhi', 'Chennai': 'Tamil Nadu'}\n",
        "df['State'] = df['City'].map(city_map)\n",
        "print(df)\n",
        "Output:\n",
        "\n",
        "markdown\n",
        "Copy code\n",
        "    City        State\n",
        "0  Mumbai  Maharashtra\n",
        "1   Delhi        Delhi\n",
        "2  Chennai   Tamil Nadu\n",
        "Mapping with a Function:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "df['City Length'] = df['City'].map(len)\n",
        "print(df)\n",
        "Output:\n",
        "\n",
        "markdown\n",
        "Copy code\n",
        "    City        State  City Length\n",
        "0  Mumbai  Maharashtra            6\n",
        "1   Delhi        Delhi            5\n",
        "2  Chennai   Tamil Nadu            7\n",
        "apply() Function\n",
        "Scope: Can be used with both Series and DataFrames.\n",
        "Use Case: Allows applying more complex functions, including lambda functions or custom functions, to each element, row, or column.\n",
        "Best For: General-purpose function application, row-wise or column-wise transformations.\n",
        "Examples of apply():\n",
        "Applying a Function to a Series:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "df['City Uppercase'] = df['City'].apply(str.upper)\n",
        "print(df)\n",
        "Output:\n",
        "\n",
        "markdown\n",
        "Copy code\n",
        "    City        State  City Length City Uppercase\n",
        "0  Mumbai  Maharashtra            6        MUMBAI\n",
        "1   Delhi        Delhi            5         DELHI\n",
        "2  Chennai   Tamil Nadu            7       CHENNAI\n",
        "Applying a Function to a DataFrame:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "df['Name and State'] = df.apply(lambda row: f\"{row['City']}, {row['State']}\", axis=1)\n",
        "print(df)\n",
        "Output:\n",
        "\n",
        "markdown\n",
        "Copy code\n",
        "    City        State  City Length City Uppercase        Name and State\n",
        "0  Mumbai  Maharashtra            6        MUMBAI  Mumbai, Maharashtra\n",
        "1   Delhi        Delhi            5         DELHI          Delhi, Delhi\n",
        "2  Chennai   Tamil Nadu            7       CHENNAI    Chennai, Tamil Nadu\n"
      ],
      "metadata": {
        "id": "yetlZ4fhpMHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#18. A What are some advanced features of NumPy?\n",
        "\n",
        "NumPy offers several advanced features that make it an essential library for numerical and scientific computing in Python. These features help optimize performance, facilitate complex operations, and simplify data manipulation.\n",
        "\n",
        "1. Broadcasting\n",
        "Definition: Broadcasting allows NumPy to perform operations on arrays of different shapes by automatically expanding one or both arrays to match compatible dimensions.\n",
        "Benefits: Eliminates the need for explicit loops, making code more concise and efficient.\n",
        "Example:\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "b = 2\n",
        "result = a * b  # Broadcasting b to match the shape of a\n",
        "print(result)   # Output: [2, 4, 6]\n",
        "2. Vectorization\n",
        "Definition: Replaces explicit Python loops with highly optimized C and Fortran code executed by NumPy, enabling faster computations.\n",
        "Benefits: Improved performance and cleaner code.\n",
        "Example:\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "result = a ** 2  # Vectorized squaring operation\n",
        "print(result)    # Output: [1, 4, 9]\n",
        "3. Advanced Indexing\n",
        "Definition: Allows for selecting and modifying elements in arrays using boolean masks, integer arrays, and more complex indexing patterns.\n",
        "Types:\n",
        "Boolean Indexing: Selects elements that satisfy a condition.\n",
        "Fancy Indexing: Uses lists/arrays of indices to access multiple elements simultaneously.\n",
        "Examples:\n",
        "Boolean Indexing:\n",
        "\n",
        "a = np.array([1, 2, 3, 4, 5])\n",
        "result = a[a > 2]  # Selects elements greater than 2\n",
        "print(result)      # Output: [3, 4, 5]\n",
        "Fancy Indexing:\n",
        "python\n",
        "Copy code\n",
        "a = np.array([10, 20, 30, 40, 50])\n",
        "indices = [0, 3, 4]\n",
        "print(a[indices])  # Output: [10, 40, 50]\n",
        "4. Structured Arrays\n",
        "Definition: Allows the creation of arrays with multiple fields (columns) of different data types.\n",
        "Use Case: Similar to working with tables or records.\n",
        "Example:\n",
        "\n",
        "data = np.array([(1, 'Alice', 25), (2, 'Bob', 30)],\n",
        "                dtype=[('id', 'i4'), ('name', 'U10'), ('age', 'i4')])\n",
        "print(data['name'])  # Output: ['Alice' 'Bob']\n",
        "5. Universal Functions (ufuncs)\n",
        "Definition: Optimized, element-wise operations that work on entire arrays.\n",
        "Examples: np.add(), np.sin(), np.exp(), np.sqrt(), etc.\n",
        "Benefits: Faster execution compared to Python's built-in functions.\n",
        "Example:\n",
        "\n",
        "a = np.array([1, 2, 3])\n",
        "result = np.sqrt(a)  # Element-wise square root\n",
        "print(result)        # Output: [1.         1.41421356 1.73205081]\n",
        "6. Linear Algebra Functions\n",
        "Definition: Functions for solving linear algebra problems, such as matrix operations, determinants, eigenvalues, and inverses.\n",
        "Key Functions: np.dot(), np.linalg.inv(), np.linalg.eig(), np.linalg.det().\n",
        "Example:\n",
        "\n",
        "A = np.array([[1, 2], [3, 4]])\n",
        "inv_A = np.linalg.inv(A)  # Inverse of matrix A\n",
        "print(inv_A)\n",
        "7. Random Number Generation\n",
        "Definition: Provides a suite of random number generators for creating arrays of random values.\n",
        "Functions: np.random.rand(), np.random.randint(), np.random.normal(), etc.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "random_array = np.random.rand(3, 3)\n",
        "print(random_array)\n",
        "8. Memory Management and Efficiency\n",
        "Feature: NumPy arrays are more memory-efficient than Python lists.\n",
        "Reason: They use contiguous memory blocks and fixed data types, reducing overhead and improving cache performance.\n",
        "9. Multi-dimensional Arrays and Manipulation\n",
        "Features:\n",
        "Array Reshaping: reshape(), ravel(), flatten().\n",
        "Array Transposing: transpose(), .T.\n",
        "Stacking and Splitting: vstack(), hstack(), split().\n",
        "Example:\n",
        "\n",
        "a = np.arange(6).reshape(2, 3)  # Reshape a 1D array to 2x3\n",
        "print(a)\n",
        "10. Broadcasting with np.newaxis\n",
        "Use Case: Adding new dimensions to arrays for broadcasting.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "a = np.array([1, 2, 3])\n",
        "a_2d = a[:, np.newaxis]  # Adds a new axis\n",
        "print(a_2d.shape)        # Output: (3, 1)"
      ],
      "metadata": {
        "id": "BAjQo85lquI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#19. How does Pandas simplify time series analysis?\n",
        "Pandas provides powerful and intuitive tools to simplify time series analysis in Python. It offers extensive functionality to handle, manipulate, and analyze time-based data. Here are some key ways in which Pandas makes time series analysis more accessible:\n",
        "\n",
        "1. DateTimeIndex and Time-based Indexing\n",
        "DateTimeIndex allows you to index your data with dates and times rather than plain integers.\n",
        "You can quickly filter and slice data by specific time ranges.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a DataFrame with a DateTime index\n",
        "dates = pd.date_range(start='2024-01-01', periods=5, freq='D')\n",
        "df = pd.DataFrame({'value': [10, 15, 20, 25, 30]}, index=dates)\n",
        "\n",
        "print(df)\n",
        "# Output:\n",
        "#             value\n",
        "# 2024-01-01     10\n",
        "# 2024-01-02     15\n",
        "# 2024-01-03     20\n",
        "# 2024-01-04     25\n",
        "# 2024-01-05     30\n",
        "\n",
        "# Slicing by date range\n",
        "print(df['2024-01-02':'2024-01-04'])\n",
        "2. Resampling and Aggregation\n",
        "Resampling allows changing the frequency of the data (e.g., converting daily data to monthly data).\n",
        "You can aggregate data during resampling (e.g., sum, mean).\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "# Resampling to sum the values weekly\n",
        "weekly_sum = df.resample('W').sum()\n",
        "print(weekly_sum)\n",
        "Common Frequencies:\n",
        "\n",
        "D: Daily\n",
        "W: Weekly\n",
        "M: Monthly\n",
        "Q: Quarterly\n",
        "Y: Yearly\n",
        "3. Handling Missing Data\n",
        "Time series often have gaps or missing timestamps. Pandas provides methods to handle this effectively:\n",
        "Filling Missing Values: fillna()\n",
        "Forward/Backward Fill: ffill() or bfill()\n",
        "Interpolate to estimate missing data points.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "df.loc['2024-01-03'] = None  # Simulating a missing value\n",
        "df_filled = df.fillna(method='ffill')  # Forward fill\n",
        "print(df_filled)\n",
        "4. Rolling and Moving Window Calculations\n",
        "Rolling allows applying functions (e.g., mean, sum) over a moving window, such as calculating moving averages.\n",
        "Useful for smoothing data or detecting trends.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "# Calculate a 3-day rolling average\n",
        "df['rolling_mean'] = df['value'].rolling(window=3).mean()\n",
        "print(df)\n",
        "5. Shifting and Lagging Data\n",
        "Pandas allows shifting data forward or backward in time, which is useful for comparing current data with past or future data.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "df['shifted'] = df['value'].shift(1)  # Shift by one period\n",
        "print(df)\n",
        "6. DateTime Conversion\n",
        "Automatic conversion of strings or other formats to datetime objects using pd.to_datetime().\n",
        "Simplifies parsing and standardizing date formats.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "date_str = '2024-01-01'\n",
        "date_obj = pd.to_datetime(date_str)\n",
        "print(date_obj)  # Output: 2024-01-01 00:00:00\n",
        "7. Time Zone Handling\n",
        "Pandas supports time zones and allows you to convert between time zones using the tz_localize() and tz_convert() methods.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "df = df.tz_localize('UTC')\n",
        "df = df.tz_convert('Asia/Kolkata')\n",
        "print(df)\n",
        "8. Periods and Frequency Management\n",
        "Periods represent intervals of time (e.g., months, quarters) rather than specific timestamps.\n",
        "Useful for aggregating data at different frequencies.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "period = pd.Period('2024-01', freq='M')\n",
        "print(period.start_time)  # Output: 2024-01-01 00:00:00\n",
        "print(period.end_time)    # Output: 2024-01-31 23:59:59.999999999\n",
        "9. Grouping by Time Intervals\n",
        "Use groupby() with time intervals for analyzing subsets of time-based data (e.g., group by month or year).\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "df['month'] = df.index.month\n",
        "monthly_group = df.groupby('month').mean()\n",
        "print(monthly_group)\n",
        "10. Plotting Time Series Data\n",
        "Pandas integrates with libraries like Matplotlib and Seaborn to visualize time series data.\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df['value'].plot(title='Time Series Plot')\n",
        "plt.show()\n",
        "Summary\n",
        "Pandas simplifies time series analysis through:\n",
        "\n",
        "Date-based indexing for easy data selection.\n",
        "Resampling for frequency conversion.\n",
        "Rolling windows for smoothing and analysis.\n",
        "Shifting and lagging for comparative analysis.\n",
        "Time zone support and missing data handling.\n",
        "Easy plotting and aggregation.\n",
        "These tools help efficiently manipulate and analyze complex time-based datasets."
      ],
      "metadata": {
        "id": "uYRL1nPXqspd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20. A What is the role of a pivot table in Pandas?\n",
        "\n",
        "In Pandas, a pivot table is used to reshape and summarize data. It allows you to reorganize a dataset,\n",
        "grouping data by certain columns and applying aggregation functions to summarize the data.\n",
        "Pivot tables are particularly useful for transforming data into a format that is easier to analyze or visualize.\n",
        "\n",
        "Key Functions of Pivot Tables in Pandas:\n",
        "Reshaping Data: Pivot tables allow you to rearrange data by turning unique values from\n",
        " one column into new columns and aggregating the values in the original columns accordingly.\n",
        "\n",
        "Summarizing Data: Pivot tables allow you to compute statistics (such as sums, means, counts) for\n",
        " subsets of the data. This is helpful in summarizing large datasets for analysis.\n",
        "\n",
        "Multi-dimensional Analysis: You can create pivot tables that summarize data across multiple dimensions,\n",
        " giving you a more granular view of the dataset.\n",
        "\n",
        "Syntax of Pivot Table in Pandas:\n",
        "python\n",
        "Copy code\n",
        "DataFrame.pivot_table(data=None, values=None, index=None, columns=None, aggfunc='mean', fill_value=None)\n",
        "data: The DataFrame containing the data.\n",
        "values: The column(s) to aggregate.\n",
        "index: Column(s) to group by (rows of the pivot table).\n",
        "columns: Column(s) to create new columns for.\n",
        "aggfunc: Aggregation function(s) to apply (e.g., 'sum', 'mean', 'count').\n",
        "fill_value: Value to replace missing values.\n",
        "Example of a Pivot Table in Pandas:\n",
        "Let's consider a dataset with sales data:\n",
        "\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Sample dataset\n",
        "data = {\n",
        "    'Date': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02', '2024-01-03'],\n",
        "    'Product': ['A', 'B', 'A', 'B', 'A'],\n",
        "    'Sales': [10, 15, 20, 25, 30],\n",
        "    'Region': ['North', 'North', 'South', 'South', 'North']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a pivot table\n",
        "pivot_table = pd.pivot_table(df, values='Sales', index='Date', columns='Product', aggfunc='sum', fill_value=0)\n",
        "\n",
        "print(pivot_table)\n",
        "Output:\n",
        "\n",
        "yaml\n",
        "Copy code\n",
        "Product          A   B\n",
        "Date\n",
        "2024-01-01      10  15\n",
        "2024-01-02      20  25\n",
        "2024-01-03      30   0\n",
        "Explanation:\n",
        "Index (Date): The rows of the pivot table are grouped by the Date column.\n",
        "Columns (Product): The unique values in the Product column (A and B) are turned into columns.\n",
        "Values (Sales): The Sales column is used to populate the table.\n",
        "Aggregation: The aggregation function used is 'sum', so it sums the sales for each date-product combination.\n",
        "Common Use Cases of Pivot Tables:\n",
        "Summarizing sales data: Grouping sales by date or region and aggregating by product type or other categories.\n",
        "Analyzing customer data: Grouping customer metrics (like purchase frequency) by customer type or region.\n",
        "Financial analysis: Grouping financial transactions by categories (e.g., revenue, expenses, and regions).\n",
        "Advanced Pivot Table Features:\n",
        "Multiple Aggregation Functions: You can apply multiple aggregation functions (e.g., sum, mean, etc.) to the same dataset.\n",
        "python\n",
        "Copy code\n",
        "pivot_table = pd.pivot_table(df, values='Sales', index='Date', columns='Product', aggfunc=['sum', 'mean'])\n",
        "Multi-level Indexing: You can group data by more than one column to create a multi-level index in the pivot table.\n",
        "python\n",
        "Copy code\n",
        "pivot_table = pd.pivot_table(df, values='Sales', index=['Date', 'Region'], columns='Product', aggfunc='sum')\n",
        "Summary:\n",
        "A pivot table in Pandas is a powerful tool for:\n",
        "\n",
        "Reshaping and aggregating data.\n",
        "Summarizing large datasets based on certain dimensions (e.g., time, category).\n",
        "Providing multi-dimensional analysis of data for better insights.\n",
        "It simplifies complex data manipulation tasks and is often used for exploratory data analysis,\n",
        "reporting, and visualizations."
      ],
      "metadata": {
        "id": "A24gVr5NrtYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#21.  Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "NumPy’s array slicing is faster than Python's list slicing due to several key differences in the way NumPy arrays and Python lists are implemented:\n",
        "\n",
        "1. Contiguous Memory Layout (NumPy) vs. Non-contiguous Memory Layout (Python lists)\n",
        "NumPy arrays are stored in a contiguous block of memory, meaning that all elements of the array are stored sequentially in memory. This makes it easy for NumPy to access and slice large blocks of data quickly, as the memory addresses of the elements are known and predictable.\n",
        "Python lists, on the other hand, are more complex data structures. A list in Python is an array of pointers to other objects (which may not be contiguous in memory). This additional level of indirection means that slicing a list involves more work, as Python needs to handle each pointer and potentially traverse different memory locations.\n",
        "2. Vectorized Operations (NumPy) vs. Iterative Operations (Python lists)\n",
        "NumPy is optimized for vectorized operations, meaning it can perform slicing without the need for explicit loops in Python. It can access and manipulate entire blocks of memory in a single operation using highly efficient C code under the hood.\n",
        "Python lists require iterative operations to slice or access elements, which leads to a slower performance because each element needs to be accessed one by one.\n",
        "3. Less Overhead in NumPy\n",
        "NumPy arrays are designed to hold elements of a single data type, allowing for a fixed memory size for each element. This reduces overhead during slicing operations.\n",
        "Python lists are heterogeneous, meaning that they can hold elements of different data types. This flexibility introduces additional overhead when slicing, as Python must handle each element individually, potentially invoking additional memory management tasks.\n",
        "4. Optimized C Implementation (NumPy)\n",
        "NumPy operations are implemented in compiled C code, which is significantly faster than Python’s interpreted execution. NumPy performs slicing in a way that minimizes Python's overhead, making use of low-level operations that are much faster than Python's default list handling.\n",
        "Python lists are implemented in pure Python with a higher level of abstraction, meaning that slicing is slower due to the higher overhead of Python’s interpreted nature.\n",
        "5. No Copying in NumPy (when slicing)\n",
        "When you slice a NumPy array, NumPy returns a view of the original array (not a copy), meaning no new data is created. This makes slicing very fast because it simply involves modifying pointers to the data rather than creating new arrays.\n",
        "In contrast, slicing a Python list often involves creating a new list, which is a more memory- and time-consuming operation.\n",
        "Example to Illustrate:\n",
        "Let's consider slicing a simple list and a NumPy array:\n",
        "\n",
        "Python List Slicing:\n",
        "python\n",
        "Copy code\n",
        "import time\n",
        "\n",
        "# Create a Python list\n",
        "python_list = list(range(1000000))\n",
        "\n",
        "# Measure time for slicing\n",
        "start_time = time.time()\n",
        "sliced_list = python_list[100:200]\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Python list slicing time:\", end_time - start_time)\n",
        "NumPy Array Slicing:\n",
        "python\n",
        "Copy code\n",
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array\n",
        "numpy_array = np.arange(1000000)\n",
        "\n",
        "# Measure time for slicing\n",
        "start_time = time.time()\n",
        "sliced_array = numpy_array[100:200]\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"NumPy array slicing time:\", end_time - start_time)\n",
        "In most cases, NumPy slicing will be faster because of the reasons mentioned above.\n",
        "\n",
        "Summary:\n",
        "NumPy’s slicing is faster than Python’s list slicing due to the contiguous memory layout of NumPy arrays,\n",
        "vectorized operations, reduced overhead, and C-level optimizations.\n",
        "Python lists are slower because they involve more complex memory management, iteration over elements,\n",
        "and potentially new object creation.\n",
        "These optimizations make NumPy particularly well-suited for large-scale data manipulation and\n",
        " scientific computing, where slicing and data handling are frequent operations."
      ],
      "metadata": {
        "id": "0-xSxfWcsIKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#22. What are some common use cases for Seaborn?\n",
        "\n",
        "Seaborn is a powerful Python data visualization library built on top of Matplotlib that simplifies the creation of complex, informative, and aesthetically pleasing visualizations. Some of the common use cases for Seaborn include:\n",
        "\n",
        "1. Exploratory Data Analysis (EDA)\n",
        "Seaborn is widely used in exploratory data analysis because it helps quickly understand relationships, distributions, and patterns in the data. Some specific use cases are:\n",
        "\n",
        "Univariate distributions: Visualizing the distribution of a single variable to understand its shape, spread, and outliers.\n",
        "\n",
        "Example: sns.histplot(), sns.kdeplot()\n",
        "Bivariate relationships: Exploring the relationship between two variables, identifying correlations or trends.\n",
        "\n",
        "Example: sns.scatterplot(), sns.kdeplot(), sns.regplot()\n",
        "Multivariate relationships: Visualizing relationships between multiple variables simultaneously.\n",
        "\n",
        "Example: sns.pairplot(), sns.heatmap(), sns.pivot_table()\n",
        "2. Categorical Data Visualization\n",
        "Seaborn excels in visualizing categorical data, especially for comparing the distributions and relationships within categories.\n",
        "\n",
        "Box plots: Used to show the distribution of a continuous variable across categories.\n",
        "\n",
        "Example: sns.boxplot()\n",
        "Violin plots: Similar to box plots, but provide more information about the distribution, such as density estimation.\n",
        "\n",
        "Example: sns.violinplot()\n",
        "Bar plots: Show the relationship between categorical variables and a numeric measure.\n",
        "\n",
        "Example: sns.barplot()\n",
        "Count plots: Visualize the count of observations in each category.\n",
        "\n",
        "Example: sns.countplot()\n",
        "Strip plots: Show individual data points along with categorical variables.\n",
        "\n",
        "Example: sns.stripplot()\n",
        "Swarm plots: Like strip plots, but show data points in a way that avoids overlap, making the distribution clearer.\n",
        "\n",
        "Example: sns.swarmplot()\n",
        "3. Heatmaps\n",
        "Seaborn is commonly used for creating heatmaps to visualize matrix-like data or correlation matrices. These are great for understanding relationships between many variables simultaneously.\n",
        "\n",
        "Correlation heatmaps: Visualizing the correlation between different numerical variables.\n",
        "\n",
        "Example: sns.heatmap()\n",
        "Cluster maps: Creating heatmaps with hierarchical clustering to group similar rows/columns.\n",
        "\n",
        "Example: sns.clustermap()\n",
        "4. Pairwise Relationships\n",
        "Seaborn allows you to easily visualize relationships between pairs of variables in datasets, which is particularly useful for identifying trends or clusters in multidimensional data.\n",
        "\n",
        "Pairplot: Visualizes pairwise relationships between multiple variables.\n",
        "Example: sns.pairplot()\n",
        "5. Time Series Analysis\n",
        "Seaborn is useful for visualizing time series data by plotting trends over time.\n",
        "\n",
        "Line plots: Ideal for showing how a continuous variable changes over time.\n",
        "\n",
        "Example: sns.lineplot()\n",
        "FacetGrid: To create multiple plots for different categories or time periods.\n",
        "\n",
        "Example: sns.FacetGrid()\n",
        "6. Facet Grids\n",
        "Seaborn's FacetGrid makes it easy to create multiple subplots based on the values of a categorical variable.\n",
        "\n",
        "FacetGrid: Used to create a grid of subplots, each representing a subset of the data.\n",
        "\n",
        "Example: sns.FacetGrid()\n",
        "FacetGrid with map(): Allows applying a plotting function to each subset of data in the grid.\n",
        "\n",
        "Example: sns.FacetGrid().map(sns.scatterplot, \"x\", \"y\")\n",
        "7. Regression Analysis\n",
        "Seaborn supports visualizing linear relationships between variables using regression models.\n",
        "\n",
        "Regression plots: Visualize a linear regression fit to data, helpful for identifying trends.\n",
        "\n",
        "Example: sns.regplot()\n",
        "Residual plots: Visualizing the residuals of a regression to assess the fit of a model.\n",
        "\n",
        "Example: sns.residplot()\n",
        "8. Statistical Visualization\n",
        "Seaborn simplifies statistical plots and displays, often including confidence intervals or statistical estimations.\n",
        "\n",
        "Error bars: Visualizing uncertainty or variability in a dataset.\n",
        "\n",
        "Example: sns.pointplot(), sns.barplot()\n",
        "Jointplot: Displays the relationship between two variables, including their univariate distributions.\n",
        "\n",
        "Example: sns.jointplot()\n",
        "9. Custom Styling and Aesthetics\n",
        "Seaborn makes it easy to create visually appealing plots with customized styles, themes, and color palettes.\n",
        "\n",
        "Styling: Seaborn allows users to adjust plot aesthetics such as background colors, font sizes, and gridlines.\n",
        "\n",
        "Example: sns.set_style(), sns.set_palette()\n",
        "Themes: It has built-in themes like \"darkgrid\", \"white\", and \"ticks\" to adjust the appearance.\n",
        "\n",
        "Example: sns.set_theme()\n",
        "10. Visualizing Distributions and Relationships with KDE\n",
        "Kernel Density Estimation (KDE) is a smooth, continuous estimate of the probability distribution of a random variable. Seaborn makes it easy to visualize this.\n",
        "\n",
        "KDE plots: Visualizing the probability density of a continuous variable.\n",
        "Example: sns.kdeplot()\n"
      ],
      "metadata": {
        "id": "Rfpo_9ROsXf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PRACTICAL"
      ],
      "metadata": {
        "id": "MZV7Lh_esxLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. <A How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "\n",
        "To create a 2D NumPy array and calculate the sum of each row, you can follow these steps:\n",
        "\n",
        "Step 1: Create the 2D NumPy array\n",
        "You can create a 2D array using np.array() or np.random functions.\n",
        "\n",
        "Step 2: Calculate the sum of each row\n",
        "You can use the np.sum() function, specifying the axis. When axis=1 is provided, it calculates the sum along the rows (i.e., summing each row's elements).\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create a 2D NumPy array (e.g., 3x3 matrix)\n",
        "array = np.array([[1, 2, 3],\n",
        "                  [4, 5, 6],\n",
        "                  [7, 8, 9]])\n",
        "\n",
        "# Step 2: Calculate the sum of each row\n",
        "row_sums = np.sum(array, axis=1)\n",
        "\n",
        "# Output the result\n",
        "print(\"2D Array:\")\n",
        "print(array)\n",
        "\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n",
        "Output:\n",
        "lua\n",
        "Copy code\n",
        "2D Array:\n",
        "[[1 2 3]\n",
        " [4 5 6]\n",
        " [7 8 9]]\n",
        "\n",
        "Sum of each row:\n",
        "[ 6 15 24]\n",
        "Explanation:\n",
        "The array [[1, 2, 3], [4, 5, 6], [7, 8, 9]] is a 3x3 matrix.\n",
        "np.sum(array, axis=1) sums each row:\n",
        "Row 1: 1 + 2 + 3 = 6\n",
        "Row 2: 4 + 5 + 6 = 15\n",
        "Row 3: 7 + 8 + 9 = 24\n",
        "Thus, the output gives the sum of each row: [6, 15, 24]."
      ],
      "metadata": {
        "id": "hmVqxSqEs3Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Write a Pandas script to find the mean of a specific column in a DataFrame?\n",
        "To calculate the mean of a specific column in a Pandas DataFrame, you can use the mean() function. Here's an example script:\n",
        "\n",
        "Example:\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a sample DataFrame\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "        'Age': [23, 45, 34, 40, 28],\n",
        "        'Salary': [70000, 80000, 120000, 95000, 85000]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Calculating the mean of the 'Age' column\n",
        "mean_age = df['Age'].mean()\n",
        "\n",
        "# Displaying the result\n",
        "print(\"Mean of 'Age' column:\", mean_age)\n",
        "\n",
        "# Optionally, you can print the entire DataFrame\n",
        "print(\"\\nDataFrame:\")\n",
        "print(df)\n",
        "Output:\n",
        "sql\n",
        "Copy code\n",
        "Mean of 'Age' column: 34.0\n",
        "\n",
        "DataFrame:\n",
        "      Name  Age  Salary\n",
        "0    Alice   23   70000\n",
        "1      Bob   45   80000\n",
        "2  Charlie   34  120000\n",
        "3    David   40   95000\n",
        "4      Eva   28   85000\n",
        "Explanation:\n",
        "The script creates a sample DataFrame df with columns 'Name', 'Age', and 'Salary'.\n",
        "The mean() function is used to calculate the mean of the 'Age' column (df['Age'].mean()), which is 34.0 in this example.\n",
        "\n",
        "#3. A Create a scatter plot using Matplotlib?\n",
        "\n",
        "To create a scatter plot using Matplotlib, you can use the plt.scatter() function. Here's an example script:\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for x and y coordinates\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y = [5, 4, 3, 2, 1]\n",
        "\n",
        "# Creating the scatter plot\n",
        "plt.scatter(x, y, color='blue', label='Data Points')\n",
        "\n",
        "# Adding title and labels\n",
        "plt.title('Scatter Plot Example')\n",
        "plt.xlabel('X-Axis')\n",
        "plt.ylabel('Y-Axis')\n",
        "\n",
        "# Displaying the legend\n",
        "plt.legend()\n",
        "\n",
        "# Showing the plot\n",
        "plt.show()\n",
        "Output:\n",
        "This will display a scatter plot where the points are plotted with x values on the horizontal axis and y values on the vertical axis.\n",
        "\n",
        "Explanation:\n",
        "plt.scatter(x, y) creates the scatter plot with the given x and y data points.\n",
        "color='blue' sets the color of the points to blue.\n",
        "label='Data Points' assigns a label to the data points for the legend.\n",
        "plt.title(), plt.xlabel(), and plt.ylabel() add a title and axis labels, respectively.\n",
        "plt.legend() displays the legend to identify the data points.\n",
        "plt.show() displays the plot.\n",
        "This will generate a simple scatter plot with points at coordinates (1, 5), (2, 4), (3, 3), (4, 2), and (5, 1)."
      ],
      "metadata": {
        "id": "31DgHwnztLeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n",
        "\n",
        "To calculate the correlation matrix using Seaborn and visualize it with a heatmap, you can use the seaborn.heatmap() function along with pandas.DataFrame.corr() to compute the correlation matrix. Here's how you can do it:\n",
        "\n",
        "Steps:\n",
        "Calculate the correlation matrix: Use pandas.DataFrame.corr() to compute the correlation matrix of the DataFrame.\n",
        "Visualize with a heatmap: Use seaborn.heatmap() to create a heatmap of the correlation matrix.\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a sample DataFrame\n",
        "data = {\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6],\n",
        "    'D': [6, 7, 8, 9, 10]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 1: Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Step 2: Visualize the correlation matrix with a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "\n",
        "# Display the plot\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "Explanation:\n",
        "df.corr() computes the correlation matrix of the DataFrame df. It calculates how each pair of columns in the DataFrame are correlated.\n",
        "sns.heatmap() is used to plot the correlation matrix as a heatmap.\n",
        "annot=True adds the correlation values to the heatmap.\n",
        "cmap='coolwarm' specifies the color palette for the heatmap.\n",
        "fmt='.2f' formats the correlation values to 2 decimal places.\n",
        "linewidths=0.5 adds a small border between the cells in the heatmap.\n",
        "plt.figure(figsize=(8, 6)) specifies the figure size for better readability.\n",
        "Output:\n",
        "This will generate a heatmap displaying the correlation coefficients between the columns in the DataFrame, with colors representing the strength of the correlation. Positive correlations are shown in warm colors (e.g., red), while negative correlations are shown in cool colors (e.g., blue)."
      ],
      "metadata": {
        "id": "lneIILqptip1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Generate a bar plot using Plotly?\n",
        "To create a bar plot using Plotly, you can use the plotly.express.bar() function, which provides an easy way to generate interactive bar charts. Here's an example script:\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import plotly.express as px\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'C', 'D', 'E'],\n",
        "    'Values': [23, 45, 56, 78, 33]\n",
        "}\n",
        "\n",
        "# Creating a DataFrame\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating a bar plot using Plotly\n",
        "fig = px.bar(df, x='Category', y='Values', title='Bar Plot Example')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "Explanation:\n",
        "plotly.express.bar() creates a bar plot where x='Category' sets the categories on the x-axis, and y='Values' sets the values that will be represented by the bars.\n",
        "title='Bar Plot Example' adds a title to the plot.\n",
        "fig.show() displays the interactive plot.\n",
        "Output:\n",
        "The output will be an interactive bar plot with the categories \"A\", \"B\", \"C\", \"D\", and \"E\" on the x-axis and their corresponding values (23, 45, 56, 78, 33) on the y-axis. The plot will be interactive, allowing you to hover over bars for additional information."
      ],
      "metadata": {
        "id": "OIMr6gC8tuuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Create a DataFrame and add a new column based on an existing column?\n",
        "To create a DataFrame and add a new column based on an existing column in Pandas, you can simply perform element-wise operations on the existing column and assign the result to a new column.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Creating a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [23, 45, 34, 40, 28],\n",
        "    'Salary': [70000, 80000, 120000, 95000, 85000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Adding a new column 'Age in 5 Years' based on the 'Age' column\n",
        "df['Age in 5 Years'] = df['Age'] + 5\n",
        "\n",
        "# Displaying the updated DataFrame\n",
        "print(df)\n",
        "Output:\n",
        "markdown\n",
        "Copy code\n",
        "      Name  Age  Salary  Age in 5 Years\n",
        "0    Alice   23   70000             28\n",
        "1      Bob   45   80000             50\n",
        "2  Charlie   34  120000             39\n",
        "3    David   40   95000             45\n",
        "4      Eva   28   85000             33\n",
        "Explanation:\n",
        "The data dictionary is used to create the initial DataFrame df.\n",
        "A new column 'Age in 5 Years' is created by adding 5 years to the values in the 'Age' column (df['Age'] + 5).\n",
        "The result is stored in the new column df['Age in 5 Years'].\n",
        "You can perform similar operations for any type of transformation based on existing columns."
      ],
      "metadata": {
        "id": "DZAz2s_Jt23P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Write a program to perform element-wise multiplication of two NumPy arrays?\n",
        "\n",
        "To perform element-wise multiplication of two NumPy arrays, you can simply use the * operator, which applies multiplication to corresponding elements of the arrays.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import numpy as np\n",
        "\n",
        "# Creating two NumPy arrays\n",
        "array1 = np.array([1, 2, 3, 4, 5])\n",
        "array2 = np.array([5, 4, 3, 2, 1])\n",
        "\n",
        "# Performing element-wise multiplication\n",
        "result = array1 * array2\n",
        "\n",
        "# Displaying the result\n",
        "print(\"Element-wise multiplication result:\", result)\n",
        "Output:\n",
        "less\n",
        "Copy code\n",
        "Element-wise multiplication result: [5 8 9 8 5]\n",
        "Explanation:\n",
        "array1 and array2 are two NumPy arrays of the same shape.\n",
        "The * operator performs element-wise multiplication between the two arrays, meaning that each element in array1 is multiplied by the corresponding element in array2.\n",
        "The result is stored in the result array and displayed.\n",
        "This method works efficiently for element-wise operations on arrays of the same shape in NumPy."
      ],
      "metadata": {
        "id": "EkjE0vdIuBl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8. A Create a line plot with multiple lines using Matplotlib?\n",
        "To create a line plot with multiple lines using Matplotlib, you can use the plot() function multiple times, each time for a different line. This allows you to plot multiple lines on the same graph.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data for the lines\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [1, 4, 9, 16, 25]   # First line\n",
        "y2 = [1, 2, 3, 4, 5]     # Second line\n",
        "y3 = [1, 8, 27, 64, 125] # Third line\n",
        "\n",
        "# Create the plot\n",
        "plt.plot(x, y1, label='y = x^2', marker='o')  # First line with marker\n",
        "plt.plot(x, y2, label='y = x', marker='s')    # Second line with marker\n",
        "plt.plot(x, y3, label='y = x^3', marker='^')  # Third line with marker\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('Y values')\n",
        "plt.title('Line Plot with Multiple Lines')\n",
        "\n",
        "# Display a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "Explanation:\n",
        "x is the common set of x-axis values for all the lines.\n",
        "y1, y2, and y3 are the y-axis values for three different lines.\n",
        "plt.plot(x, y, label='label_name') is used to plot each line, where label='label_name' helps to add a label for the legend.\n",
        "marker='o', marker='s', and marker='^' specify different markers for each line (optional).\n",
        "plt.legend() displays the legend to distinguish between the different lines.\n",
        "plt.xlabel(), plt.ylabel(), and plt.title() add labels to the axes and the title to the plot.\n",
        "Output:\n",
        "This will display a line plot with three lines, each representing a different mathematical function (x^2, x, and x^3), with a legend to differentiate them."
      ],
      "metadata": {
        "id": "fiIFx2gQuOQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#9. A Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold?\n",
        "To generate a Pandas DataFrame and filter rows based on a column value being greater than a certain threshold, you can use conditional filtering with boolean indexing.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
        "    'Age': [23, 45, 34, 40, 28],\n",
        "    'Salary': [70000, 80000, 120000, 95000, 85000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the threshold value for Salary\n",
        "threshold = 90000\n",
        "\n",
        "# Filter rows where the Salary is greater than the threshold\n",
        "filtered_df = df[df['Salary'] > threshold]\n",
        "\n",
        "# Display the filtered DataFrame\n",
        "print(filtered_df)\n",
        "Output:\n",
        "markdown\n",
        "Copy code\n",
        "      Name  Age  Salary\n",
        "2  Charlie   34  120000\n",
        "3    David   40   95000\n",
        "4      Eva   28   85000\n",
        "Explanation:\n",
        "A DataFrame df is created from a dictionary of data.\n",
        "We set the threshold value for the column 'Salary' to 90000.\n",
        "df[df['Salary'] > threshold] is used to filter the rows where the value in the 'Salary' column is greater than 90000. This returns a new DataFrame containing only the rows that meet this condition.\n",
        "The filtered DataFrame filtered_df is displayed.\n",
        "This method can be adapted to filter based on any column or condition."
      ],
      "metadata": {
        "id": "ejgK-HhvucZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#10. Create a histogram using Seaborn to visualize a distribution?\n",
        "To create a histogram using Seaborn to visualize a distribution, you can use the seaborn.histplot() function. This function helps to visualize the distribution of a dataset by dividing the data into bins and plotting the frequency of data points in each bin.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data: a list of numbers (e.g., ages)\n",
        "data = [23, 45, 34, 40, 28, 33, 35, 45, 50, 60, 32, 38, 47, 42, 30]\n",
        "\n",
        "# Create a Seaborn histogram\n",
        "sns.histplot(data, kde=True, bins=10, color='skyblue', edgecolor='black')\n",
        "\n",
        "# Add title and labels\n",
        "plt.title('Histogram of Ages')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "Explanation:\n",
        "sns.histplot(data) creates the histogram for the data.\n",
        "The kde=True argument adds a Kernel Density Estimate (KDE) curve to visualize the distribution smoothly.\n",
        "bins=10 specifies the number of bins in the histogram. You can adjust this number based on how granular you want the distribution.\n",
        "color='skyblue' and edgecolor='black' set the colors for the histogram bars and their edges, respectively.\n",
        "plt.title(), plt.xlabel(), and plt.ylabel() are used to add a title and labels to the axes.\n",
        "Output:\n",
        "This will generate a histogram visualizing the distribution of the data, along with a smooth KDE curve, allowing you to better understand the underlying distribution."
      ],
      "metadata": {
        "id": "uKTC6HkxulE1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#11. A Perform matrix multiplication using NumPy?\n",
        "\n",
        "To perform matrix multiplication using NumPy, you can use the np.dot() function or the @ operator (introduced in Python 3.5). Both methods perform matrix multiplication between two 2D arrays (matrices).\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import numpy as np\n",
        "\n",
        "# Create two matrices (2D arrays)\n",
        "matrix1 = np.array([[1, 2], [3, 4]])\n",
        "matrix2 = np.array([[5, 6], [7, 8]])\n",
        "\n",
        "# Perform matrix multiplication using np.dot()\n",
        "result = np.dot(matrix1, matrix2)\n",
        "\n",
        "# Alternatively, you can use the @ operator (equivalent to np.dot)\n",
        "# result = matrix1 @ matrix2\n",
        "\n",
        "# Display the result\n",
        "print(\"Result of matrix multiplication:\")\n",
        "print(result)\n",
        "Output:\n",
        "lua\n",
        "Copy code\n",
        "Result of matrix multiplication:\n",
        "[[19 22]\n",
        " [43 50]]\n",
        "Explanation:\n",
        "matrix1 and matrix2 are two 2x2 matrices.\n",
        "np.dot(matrix1, matrix2) performs matrix multiplication.\n",
        "Matrix multiplication is performed by taking the dot product of rows from the first matrix and columns from the second matrix.\n",
        "The result is a new matrix with the product of the two matrices.\n",
        "In this case:\n",
        "\n",
        "[\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "]\n",
        "⋅\n",
        "[\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "]\n",
        "=\n",
        "[\n",
        "(\n",
        "1\n",
        "⋅\n",
        "5\n",
        "+\n",
        "2\n",
        "⋅\n",
        "7\n",
        ")\n",
        "(\n",
        "1\n",
        "⋅\n",
        "6\n",
        "+\n",
        "2\n",
        "⋅\n",
        "8\n",
        ")\n",
        "(\n",
        "3\n",
        "⋅\n",
        "5\n",
        "+\n",
        "4\n",
        "⋅\n",
        "7\n",
        ")\n",
        "(\n",
        "3\n",
        "⋅\n",
        "6\n",
        "+\n",
        "4\n",
        "⋅\n",
        "8\n",
        ")\n",
        "]\n",
        "=\n",
        "[\n",
        "19\n",
        "22\n",
        "43\n",
        "50\n",
        "]\n",
        "[\n",
        "1\n",
        "3\n",
        "​\n",
        "\n",
        "2\n",
        "4\n",
        "​\n",
        " ]⋅[\n",
        "5\n",
        "7\n",
        "​\n",
        "\n",
        "6\n",
        "8\n",
        "​\n",
        " ]=[\n",
        "(1⋅5+2⋅7)\n",
        "(3⋅5+4⋅7)\n",
        "​\n",
        "\n",
        "(1⋅6+2⋅8)\n",
        "(3⋅6+4⋅8)\n",
        "​\n",
        " ]=[\n",
        "19\n",
        "43\n",
        "​\n",
        "\n",
        "22\n",
        "50\n",
        "​\n",
        " ]\n",
        "This is the resulting matrix from the multiplication."
      ],
      "metadata": {
        "id": "udYT9fMEuxFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#12.A Use Pandas to load a CSV file and display its first 5 rows?\n",
        "\n",
        "To load a CSV file using Pandas and display its first 5 rows, you can use the pd.read_csv()\n",
        " function to load the data and the .head() method to view the first few rows.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('your_file.csv')  # Replace 'your_file.csv' with your actual file path\n",
        "\n",
        "# Display the first 5 rows of the DataFrame\n",
        "print(df.head())\n",
        "Explanation:\n",
        "pd.read_csv('your_file.csv') loads the CSV file into a Pandas DataFrame.\n",
        " Make sure to replace 'your_file.csv' with the actual path to your CSV file.\n",
        "df.head() returns the first 5 rows of the DataFrame. You can pass an integer to head()\n",
        "to specify the number of rows you want to see (e.g., df.head(10) for the first 10 rows).\n",
        "Output Example:\n",
        "If the CSV file contains a dataset with columns like Name, Age, and Salary, the output might look like this:\n",
        "\n",
        "markdown\n",
        "Copy code\n",
        "      Name  Age  Salary\n",
        "0    Alice   23   70000\n",
        "1      Bob   45   80000\n",
        "2  Charlie   34  120000\n",
        "3    David   40   95000\n",
        "4      Eva   28   85000\n",
        "This will display the first 5 rows of the CSV file, allowing you to inspect the data."
      ],
      "metadata": {
        "id": "AEvkJN_SvA2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#13. A Create a 3D scatter plot using Plotly?\n",
        "\n",
        "To create a 3D scatter plot using Plotly, you can use the plotly.express.scatter_3d() function.\n",
        "This function allows you to plot data points in three dimensions,\n",
        "with each axis representing one of the data variables.\n",
        "\n",
        "Example Code:\n",
        "python\n",
        "Copy code\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data\n",
        "data = {\n",
        "    'X': [1, 2, 3, 4, 5],\n",
        "    'Y': [10, 11, 12, 13, 14],\n",
        "    'Z': [20, 21, 22, 23, 24]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Create a 3D scatter plot\n",
        "fig = px.scatter_3d(df, x='X', y='Y', z='Z', title='3D Scatter Plot')\n",
        "\n",
        "# Show the plot\n",
        "fig.show()\n",
        "Explanation:\n",
        "df is a DataFrame containing the data for the X, Y, and Z coordinates of the points in the scatter plot.\n",
        "px.scatter_3d(df, x='X', y='Y', z='Z') creates the 3D scatter plot using the X, Y, and Z columns from the DataFrame.\n",
        "The title argument adds a title to the plot.\n",
        "fig.show() displays the plot in a browser or Jupyter notebook.\n",
        "Output:\n",
        "The 3D scatter plot will show data points in three-dimensional space, where each axis corresponds to one of the variables\n",
        " (X, Y, and Z). You can interact with the plot to rotate it and explore the data from different angles.\n",
        "\n",
        "You can also customize the appearance of the plot by adding more attributes (like color, size, or markers)\n",
        "depending on the data."
      ],
      "metadata": {
        "id": "iiG-bJcgvKED"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}